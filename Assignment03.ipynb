{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification based on 3 layers neural network\n",
    "#### author: Kim Jeong Min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "\n",
    "\n",
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = 'horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=False, num_workers=1)  \n",
    "\n",
    "\n",
    "validation_data_path = 'horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=1, shuffle=False, num_workers=1)  \n",
    "\n",
    "IMAGE_VECTOR_SIZE = 10000\n",
    "\n",
    "train_data = np.empty((IMAGE_VECTOR_SIZE,0))\n",
    "train_label = np.empty((0,1))\n",
    "validation_data = np.empty((IMAGE_VECTOR_SIZE,0))\n",
    "validation_label = np.empty((0,1))\n",
    "\n",
    "# load training images of the batch size for every iteration\n",
    "for i, data in enumerate(trainloader):\n",
    "    # inputs is the image\n",
    "    # labels is the class of the image\n",
    "    inputs, labels = data\n",
    "    # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "    train_data = np.hstack((train_data, np.reshape(inputs, (10000,1))))\n",
    "    # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "    # human: 1, horse: 0\n",
    "    train_label = np.append(train_label, 1 if sum(labels)>0 else 0)  \n",
    "\n",
    "# load validation images of the batch size for every iteration\n",
    "for i, data in enumerate(valloader):\n",
    "    # inputs is the image\n",
    "    # labels is the class of the image\n",
    "    inputs, labels = data\n",
    "    # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "    validation_data = np.hstack((validation_data, np.reshape(inputs, (10000,1))))\n",
    "    # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "    # human: 1, horse: 0\n",
    "    validation_label = np.append(validation_label, 1 if sum(labels)>0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### add a row(np.ones) in data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_num = len(train_data[0])\n",
    "validation_data_num = len(validation_data[0])\n",
    "train_offset_ones = np.ones((1,train_data_num))\n",
    "validation_offset_ones = np.ones((1,validation_data_num))\n",
    "\n",
    "train_set = np.insert(train_data, IMAGE_VECTOR_SIZE, train_offset_ones, 0)\n",
    "validation_set = np.insert(validation_data, IMAGE_VECTOR_SIZE, validation_offset_ones, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_backward(da, z):\n",
    "    sig = sigmoid(z)\n",
    "    return da * sig * (1 - sig)\n",
    "\n",
    "def get_acc(discri, label):\n",
    "    prediction = np.round(discri)\n",
    "    equality = np.equal(prediction, label)\n",
    "    return sum(equality[0]) / len(equality[0])\n",
    "\n",
    "def get_loss(discri, label):\n",
    "    return np.average(-label*np.log(discri) - (1-label)*np.log(np.ones(discri.shape)-discri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### neural network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = IMAGE_VECTOR_SIZE\n",
    "SECOND_DIM = 20\n",
    "THIRD_DIM = 5\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "# add 1 offset dimension to input\n",
    "nn_struct = [\n",
    "    {'in_dim': INPUT_DIM + 1, 'out_dim': SECOND_DIM},\n",
    "    {'in_dim': SECOND_DIM + 1, 'out_dim': THIRD_DIM},\n",
    "    {'in_dim': THIRD_DIM + 1, 'out_dim': OUTPUT_DIM}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### gradient descent on vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_struct[0]['W'] = np.zeros((INPUT_DIM + 1, SECOND_DIM))\n",
    "nn_struct[0]['W'] = np.zeros((SECOND_DIM + 1, THIRD_DIM))\n",
    "nn_struct[0]['W'] = np.zeros((THIRD_DIM + 1, OUTPUT_DIM))\n",
    "\n",
    "MAX_ITER = 10000\n",
    "LR = 0.002\n",
    "\n",
    "train_acc = list()\n",
    "validation_acc = list()\n",
    "train_loss = list()\n",
    "validation_loss = list()\n",
    "\n",
    "prev_loss = 0\n",
    "\n",
    "for iter_num in range(0, MAX_ITER):\n",
    "    # forward propagation\n",
    "    discri = train_set\n",
    "    validation_discri = validation_set\n",
    "    for layer in nn_struct:\n",
    "        discri = sigmoid(np.dot(np.transpose(layer['W']), discri))\n",
    "        validation_discri = sigmoid(np.dot(np.transpose(layer['W']), validation_discri))\n",
    "    \n",
    "    train_acc.append(get_acc(discri, train_label))\n",
    "    loss = get_loss(discri, train_label)\n",
    "    train_loss.append(loss)\n",
    "    if abs(prev_loss - loss) < 0.00001:\n",
    "        break\n",
    "    prev_loss = loss\n",
    "    validation_acc.append(get_acc(validation_discri, validation_label))\n",
    "    validation_loss.append(get_loss(validation_discri, validation_label))\n",
    "    \n",
    "    # back propagation\n",
    "    h_vector = np.transpose(discri - np.transpose(train_label))\n",
    "    descent = np.dot(train_set, h_vector) / train_data_num\n",
    "    u_vector = u_vector - LR * descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### plot Accuracy, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc, color='#ff0000', label='Train Accuracy')\n",
    "plt.plot(validation_acc, color='#0000ff', label='Validation Accuracy')\n",
    "plt.legend(['Train Accuracy','Validation Accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_loss, color='#ff0000', label='Train Accuracy')\n",
    "plt.plot(validation_loss, color='#0000ff', label='Validation Accuracy')\n",
    "plt.legend(['Train Loss','Validation Loss'])\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### plot result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx, ny = 3, 3\n",
    "data = (('dataset', 'loss', 'accuracy'), ('train', str(round(train_loss[-1],4)), str(round(train_acc[-1],4))), ('validation', str(round(validation_loss[-1],4)), str(round(validation_acc[-1],4))))\n",
    "pl.figure()\n",
    "tb = pl.table(cellText=data, loc=(0,0), cellLoc='center')\n",
    "\n",
    "tc = tb.properties()['child_artists']\n",
    "for cell in tc: \n",
    "    cell.set_height(1/ny)\n",
    "    cell.set_width(1/nx)\n",
    "\n",
    "ax = pl.gca()\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
